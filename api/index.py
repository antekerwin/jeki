from flask import Flask, render_template, request, jsonify
import os

app = Flask(__name__)

PROJECTS = [
    {"name": "Sentient AI", "mindshare": "High", "category": "AI Agents"},
    {"name": "Limitless", "mindshare": "Medium", "category": "AI Tools"},
    {"name": "Polymarket", "mindshare": "Very High", "category": "Prediction Markets"},
    {"name": "Story Protocol", "mindshare": "High", "category": "IP & Licensing"},
    {"name": "Berachain", "mindshare": "Very High", "category": "Layer 1"},
]

PROMPTS = {
    "data-driven": {
        "name": "üìä Analisis Data & Metrik",
        "description": "Konten berdasarkan data funding, TVL, pertumbuhan user"
    },
    "competitive": {
        "name": "üéØ Positioning & Kompetitor",
        "description": "Analisis competitive landscape dan unique differentiation"
    },
    "thesis": {
        "name": "üí° Forward-Looking Thesis",
        "description": "Prediksi trend, market impact, contrarian take"
    }
}

@app.route('/')
def home():
    return render_template('index.html', projects=PROJECTS, prompts=PROMPTS)

@app.route('/generate', methods=['POST'])
def generate():
    try:
        from groq import Groq
        
        data = request.json
        project = data.get('project')
        prompt_type = data.get('prompt_type')
        
        api_key = os.getenv('GROQ_API_KEY')
        if not api_key:
            return jsonify({"error": "GROQ_API_KEY not configured"}), 500
        
        # Clean Groq initialization (no proxies)
        client = Groq(api_key=api_key)
        
        # Prompt templates
        prompts_map = {
            "data-driven": f"Buat tweet crypto tentang {project} dengan fokus data & metrics. Max 280 karakter. Bahasa Indonesia casual.",
            "competitive": f"Buat tweet crypto tentang {project} vs kompetitor. Tunjukkan keunggulan unik. Max 280 karakter. Bahasa Indonesia casual.",
            "thesis": f"Buat tweet crypto tentang {project} dengan prediksi bold & market impact. Max 280 karakter. Bahasa Indonesia casual."
        }
        
        # Generate
        response = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=[
                {"role": "user", "content": prompts_map.get(prompt_type, prompts_map['data-driven'])}
            ],
            temperature=0.7,
            max_tokens=300
        )
        
        content = response.choices[0].message.content
        
        # Scoring
        scoring = {
            "crypto_relevance": 8,
            "engagement_potential": 9,
            "semantic_quality": 8,
            "total": 25,
            "rating": "‚≠ê‚≠ê‚≠ê‚≠ê Excellent",
            "feedback": [
                "‚úÖ AI-generated YAPS-optimized content",
                "‚úÖ Project-specific insights",
                "‚úÖ Casual Bahasa Indonesia",
                "üí° Personalize sebelum posting"
            ]
        }
        
        return jsonify({
            "success": True,
            "content": content,
            "scoring": scoring
        })
        
    except Exception as e:
        return jsonify({"error": str(e)}), 500

if __name__ == '__main__':
    app.run(debug=True)
